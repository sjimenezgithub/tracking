\def\year{2017}\relax
%File: formatting-instruction.tex
\documentclass[letterpaper]{article} %DO NOT CHANGE THIS
\usepackage{aaai18}  %Required
\usepackage{times}  %Required
\usepackage{helvet}  %Required
\usepackage{courier}  %Required
\usepackage{url}  %Required
\usepackage{graphicx}  %Required
\frenchspacing  %Required
\setlength{\pdfpagewidth}{8.5in}  %Required
\setlength{\pdfpageheight}{11in}  %Required
%PDF Info Is Required:
  \pdfinfo{}
\setcounter{secnumdepth}{0}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage{tikz}
\usepackage{comment}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}

\lstset{
  basicstyle=\ttfamily,
  mathescape
}


\usepackage{multicol}
\usepackage{arydshln}
\usetikzlibrary{calc,backgrounds,positioning,fit}


\newcommand{\tup}[1]{{\langle #1 \rangle}}

\newcommand{\pre}{\mathsf{pre}}     % precondition
\newcommand{\del}{\mathsf{del}}     % effect
\newcommand{\add}{\mathsf{add}}     % effect
\newcommand{\eff}{\mathsf{eff}}     % effect
\newcommand{\cond}{\mathsf{cond}}   % conditional effect
\newcommand{\true}{\mathsf{true}}   % true
\newcommand{\false}{\mathsf{false}} % false
\newcommand{\PE}{\mathrm{PE}}     % precondition
\newcommand{\strips}{\textsc{Strips}}     % precondition


\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}


\begin{document}

\title{Model-based Multi-agent Tracking}

% Commented for blind submission
%\author{Sergio Jim\'enez\\
%{\small Departamento de Sistemas Inform\'aticos y Computaci\'on}\\
%{\small Universitat Polit\`ecnica de Val\`encia.}\\
%{\small Camino de Vera s/n. 46022 Valencia, Spain}\\
%{\small \{agarridot,serjice\}@dsic.upv.es}}



\maketitle
\begin{abstract}
\end{abstract}


\section{Introduction}
\label{sec:introduction}

{\em Multi-agent tracking} is the task of locating multiple moving objects (the agents) over time. In such task, the assumption of having fully observable trajectories of the moving objects means that the sensors are able to capture every state change at every instant, which typically is unrealistic. Normally obtaining sensor feedback (or the processing of the sensor readings) is associated with a given sampling frequency that misses intermediate data between two subsequent sensor readings.

This work exploits (1), a movement model of the agents to track and (2), an off-the-shelf classical planner, to produce reliable multi-agent tracking (even when there is a significant amount of missing sensor data). The paper formalizes the {\em Model-based Multi-Agent Tracking} task and shows that this task is addressable with an off-the-shelf classical planner. Last but not least the paper shows the applicability of this approach for tracking ants.


\section{Background}
\label{sec:background}
This section defines the planning model and the observation model that we follow in this work.

\subsection{The Classical Planning Model}
We define a {\em classical planning} problem as a tuple $P=\tup{X,I,G,A}$:
\begin{itemize}
\item $X$, is the set of {\em state variables} such that each variable $x\in X$ has an associated finite domain $D(x)$ defining the set of possible values that the variable can take. The set of possible states $S$ in a classical planning problem $P$ is then given by the {\em Cartesian product} of the size of the domain variables.
\item $I$ is the {\em initial state}, a full assignment to the variables in $X$ that is compatible with their respective domains.
\item $G$ a conjunction of {\em goal conditions} where each $g\in G$ expresses as different Boolean condition over the state variables in $X$, that is $g:S\rightarrow \{0,1\}$.
\item $A$ is the set of actions. The semantics of actions $a\in A$ is expressed with two functions:
\begin{itemize}
\item The {\em applicability function} $\alpha:A\times S\rightarrow \{0,1\}$ which determines if a given action $a\in A$ is applicable in a given state $s\in S$.
\item The {\em transition function} $\theta:A\times S\rightarrow S$ determining which is the successor state $\theta(s,a)$ that results after applying action $a\in A$ at the current state $s\in S$.
\end{itemize}
\end{itemize}

A {\em plan} for a classical planning problem $P$ is an action sequence $\pi=\tup{a_1, \ldots, a_n}$ that induces the {\em state trajectory} $s=\tup{s_0, s_1, \ldots, s_n}$ such that $s_0=I$ and, for each {\small $1\leq i\leq n$}, $a_i$ is applicable in $s_{i-1}$ and generates the successor state $s_i=\theta(s_{i-1},a_i)$. The {\em plan length} is denoted with $|\pi|=n$ . A plan $\pi$ {\em solves} $P$ iff $G\subseteq s_n$, i.e.,~if all the goal conditions are satisfied at the last state reached after following the application of the plan $\pi$ in the initial state $I$. A solution plan for $P$ is {\em optimal} if it has minimum length.

\subsection{The Observation Model}
Given a classical planning problem $P=\tup{X,I,G,A}$, we define $\omega_s=obs(s)$ as the observation of a state $s\in S$ which is as a partial assignment of the state variables in $X$. In this work we assume that state observations are noiseless, this means the variable values given by $\omega_s$ are correct while the value of some variables in $X$ may be unknown.

Now, we define the observation of the execution of a plan $\pi$ that solves $P$ as a sequence $\Omega_\pi=\tup{obs(s_0), \ldots, obs(s_m)}$ of {\em partially-observed} states. Because of the partial observability $0\leq |\Omega_\pi|\leq |\pi|+1$ and hence, the transitions between two consecutive observed states may involve the execution of more than a single action. Formally $\theta(s_i,\tup{a_1,\ldots,a_k})=s_{i+1}$, where $k\geq 1$ is unknown and unbound. This means that having $\Omega_\pi$ does not implies knowing the actual length of $\pi$.

We say that a given plan $\pi$ is {\em compliant} with a given sequence $\Omega_\pi=\tup{obs(s_0), \ldots, obs(s_m)}$ of {\em partially-observed} states iff $\Omega_\pi$ is the same sequence of states traversed by $\pi$ but:
\begin{enumerate}
\item with certain states omitted and/or,
\item the value of certain fluents omitted in that states, i.e.~$|\omega_{s_i}|\leq |X|$ for every $0\leq i\leq m$.
\end{enumerate}

\section{Model-based Multi-Agent Tracking}
\label{sec:tracking}

{\em Model-based Multi-Agent Tracking} is the task of locating $k$ moving objects by building the most plausible explanation of their trajectories that is compliant with (1), a model of the objects movement and (2), a given set of observations.

Formally the inputs to the {\em Model-based k-Agent Tracking} task are $\mathcal{T}=\tup{\Lambda, \mathcal{M}, \Omega}$, where:
\begin{itemize}
\item $\Lambda=\{\lambda_1,\ldots,\lambda_k\}$, is a set of labels to uniquely identify each of the $k$-agents.
\item $\Omega=\tup{obs(s_0), \ldots, obs(s_m)}$, is a sequence of state observations . This observations express the configurations of the different agents to track, in all this observations agents are unlabeled. 
\item $\mathcal{M}$ the agent model. This model represents the space of the possible configurations of an agent. The agent model is implicitly represented using two elements:
\begin{itemize}
\item $X_\mathcal{M}$, a finite set of variables with their corresponding domain.
\item The functions defining the possible updates of the agent variables between to subsequent time-stamps $t$ and $t+1$. 
\end{itemize}
\end{itemize}

The output to the {\em Model-based Multi-Agent Tracking} task is, for each agent, a probability distribution $P(\lambda|\Omega,\mathcal{M})$ of the possible labels that the agent can have given the observations and the agent models.

To illustrate this, Figure~\ref{fig:observation} shows an example of four observations of the 2D coordinates of ten agents (at time-stamps t1, t2 and t3 the coordinates of some of the ten agents are missing because they are unknown). Note that observations in the same row do not necessary refer to the same agent (the agents identity is unknown). This task requires ten labels to uniquely identify the different agents and the agent model is given by to discrete variables $X,Y$ that models the current position of the agent and the following action model $\{x_{t+1}=x_t + 1, x_{t+1}=x_t - 1, y_{t+1}=y_t + 1, y_{t+1}=y_t - 1\}$ that represent the possible updates of the $X,Y$ between to subsequent time-stamps.


\begin{figure}
\begin{scriptsize}
\begin{verbatim}
t0     t1     t2     t3
X  Y   X  Y   X  Y   X  Y
33 33  71 23  30 54  43 10
72 22  95 11  93 89  59 36
19 93  86 05  21 18  18 38
58 65  06 60  67 94  78 60
83 61  75 76  23 19  68 54
16 53  17 98  41 59  59 96
02 97  89 11  51 84  86 08
75 23         79 69  87 60
74 01         36 13
66 49
\end{verbatim}
\end{scriptsize}
 \caption{\small 2D coordinates for ten agents in four subsequent time-stamps (at t1, t2 and t3 some readings are missing).}
\label{fig:observation}
\end{figure}


\subsection{Explaining observations with Classical Planning}
Given an agent model $\mathcal{M}$ and a set of observations $\Omega=\tup{obs(s_0), \ldots, obs(s_m)}$, we can build a classical planning problem $P=\tup{X,I,G,A}$ such that a solution plan to this problem is an explanation of the input state observations and an optimal solution plan to this problem is the smallest explanation for given input observations and agent model.

The classical planning problem $P=\tup{X,I,G,A}$ for explaining a set of observations $\Omega=\tup{obs(s_0), \ldots, obs(s_m)}$ with an agent model $\mathcal{M}$ is built as follows:
\begin{enumerate}
\item The set of state variables $X$ is build defining a set of variables $X_\mathcal{M}$ for each agent in the observations. In addition an extra state variable $X_t$ with discrete domain $[0,m]$ is added to keep track of the current time-stamp.
\item The initial state $I$ is a full assignment of the agent variables for each of the agents (note that in t0 the 2D coordinates of all agents are known).
\item The set of goals $G$ is a conjunction of the conditions forcing the plan to generate the observations at their precise times-stamp. For instance, for the time stamp $t1$ we have 7 conditions over the X variables of the agents and another 7 over the Y variables.
\item The set of actions models the functions defining the possible updates of the agent variables between to subsequent time-stamps $t$ and $t+1$. 
\end{enumerate}

Figure~\ref{fig:plan} shows a three steps plan that is {\em compliant} with the agent model described in the previous example and the observations given in Figure~\ref{fig:observation}.


\begin{figure}
\begin{scriptsize}
\begin{verbatim}
0: dec-x(a1,l14,l13) dec-x(a2,l10,l9) dec-y(a3,l11,l10) 
dec-y(a4,l13,l12) dec-y(a5,l8,l7) inc-x(a6,l5,l6) 
inc-x(a7,l6,l7) inc-x(a8,l2,l3) inc-x(a9,l3,l4) 
inc-x(a10,l5,l6) 

1: dec-x(a1,l14,l13) dec-x(a2,l10,l9) dec-y(a3,l11,l10) 
dec-y(a4,l13,l12) dec-y(a5,l8,l7) inc-x(a6,l5,l6) 
inc-x(a7,l6,l7) inc-x(a8,l2,l3) inc-x(a9,l3,l4) 
inc-x(a10,l5,l6) 

2: dec-x(a1,l14,l13) dec-x(a2,l10,l9) dec-y(a3,l11,l10) 
dec-y(a4,l13,l12) dec-y(a5,l8,l7) inc-x(a6,l5,l6) 
inc-x(a7,l6,l7) inc-x(a8,l2,l3) inc-x(a9,l3,l4) 
inc-x(a10,l5,l6) 
\end{verbatim}
\end{scriptsize}
 \caption{\small Plan simulating the movement of ten agents in a grid.}
\label{fig:plan}
\end{figure}





\subsection{Model-based Multi-agent Tracking with Classical Planning}
Here we show that the probability distribution $P(\lambda|\Omega,\mathcal{M})$ that solves a {\em Model-based Multi-Agent Tracking} can be estimated using an off-the-shelf classical planning problem.


\section{Evaluation: Ants tracking}
\label{sec:evaluation}




\section{Conclusions}
\label{sec:conclusions}

\bibliographystyle{aaai}
\bibliography{tmodeling}

\end{document}
